---
layout: post
title : MachineLearing学习笔记(11)--关联分析
description : MachineLearing学习笔记(11)--关联分析(Apriori,FP-Growth)
category : 研究
tags : MachineLearning study-note Python
keywords : 
---

## 关联分析

### 频繁模式
所谓频繁模式，频繁项集，从字面上就可以理解，频繁出现的一些模式，集合等。

一个经典例子便是购物篮分析，在用户购物之后，记录每个篮子里的物品信息，便可以分析得到用户最有可能同时购买哪些物品。比较经典的便是面包和牛奶经常被同时购买等。那么商家便可以通过这些经验，调整商店物品布局，比如把面包和牛奶放得很近，刺激消费，在买了面包之后，看到牛奶，也许就会再购买牛奶。

我们用支持度来衡量，即数据库中有事务的集合(在购物篮分析中，每个篮子便是一个事物，篮子里有若干物品，便是项)。对于某个项集S，支持度定义为P(S)。其中包含K个项的项集称为K-项集，对于一个2-项集{A,B}，支持度定义为P(A & B)，而P(S) > min\_suppot的项集称为频繁项集，其中min\_support定义为最小支持度阈值。另外，支持度可以用绝对频率，也可以用相对频率(即概率)。

### 关联规则
字面上理解就是一些项的关联性，上面说的频繁模式可以认为是关联规则的一部分。

同样是购物篮分析，我们还可以分析出其它的规则，比如说著名的啤酒与尿布的案例，有许多男士在购买尿布之后，会顺手买了啤酒。再比如说，在购买电脑之后，很多人会买外设与相关软件。可以理解为是一种指向性，后继性。用A->B来表示。用户在购买A之后，很大可能会购买B。因此不仅A,B是频繁项集，而且还有一定的“顺序性”。

我们用置信度来衡量，对于A->B，置信度定义为P(AB)/P（A）,即条件概率，也是很好理解的，P(AB)是支持度。如果大于最小置信度阈值，那么我们认为这是一个强关联规则。

### 挖掘过程
1.  找出所有的频繁项集。
2.  由频繁项集生成强关联规则。

## Apriori算法

### 简述
这是一种通过限制候选集生成频繁项集的方法。而且这是一咱逐层搜索的迭代方法，通过k频繁项集生成k+1频繁项集的方法 。

首先说一个结论，对于一个频繁项集，它的所有子集肯定也是频繁的，<del>这个似乎很显然</del>。

那么我们也可以得到另外一个，两个集合，如果有一个非频繁，那么它们的并集也必然是非频繁的。

### 过程

因为Apriori算法的流程便是，先找到1频繁项集。然后将1频繁项集两两合并，成2项集，对每个2项集计算支持度，便得到2频繁项集，以此类推，直到为空。便得到了所有频繁项集。

具体流程中有两个步骤：
1.  连接，表示将k项集的自身连接，得到k+1项集。其实可以认为是集合的两两求并，然后提取出k+1项集。。。但是显然这样不够优越。具体做法是，我们将k项集中的项排序，使得每个项集里的项根据某个特定的规则排列。那么对于k项集到k+1项集，只是添加了一项。所以两个项集可合并，必然有k-1个项是相同的，所以我们只需要判断两个集合的前k-1项相同，便把某个集合的最后一项添加到另外一个中，便形成了k+1项集。因为排过序了，所以l_i和l_j不可以合并的话(j>i)，那么l_i和l_k肯定也不能合并(k>j)。这样就不必须做完整的O(n^2)枚举，而且也不需要做两个集合的并然后再判断是否为k+1项集。

2.  剪枝，得到k+1项集之后，可以对每个项集去求支持度，然后和最小支持度比较。但是我们发现求支持度需要和整个数据库的事务去求子集关系，过于复杂。可以提前加个剪枝。k+1项集有k+1个k子集，通过我们之前说的结构，这k+1个子集都必然是频繁的，必然是属于k频繁项集中。所以可以先做一次这样的剪枝判断。

至于挖掘强关联规则的话，直接将频繁项集分成两个集合，假设频繁项集为S，分成两个集合A,B，且A&B=null，A|B=S，那么A->B的置信度便可以通过support (A&B)/support (A)得到。以些可以判断是否强关联。

### 优点
可以得到所有的频繁项集以及相应的支持度，然后得到相应的强关联规则以及相应的置信度。

### 缺点
需要频繁遍历数据库中的事务，耗时很大。而且一般情况下事务集合非常大。

## FP-Growth

### 简述
虽然Apriori可以完成关联分析，但是因为频繁遍历事务集合，显得耗时太大。FP-Growth只需要遍历一两次。

FP-Growth挖掘出频繁项集，但是不生成候选集。

### FP树
对于每个事条，若干个项形成一个字符串，而这些字符串我们可以通过树结构存储，类似Trie的方法。这样就压缩了很多结点，合并了很多的前缀。

具体做法就是同样类似Apriori，生成1频繁项集，根据出现的频率，对事务的项进行排序，然后将这些事务相应插入到FP树中，类似Trie的插入，尽可能的合并前缀。

![FPtree](/images/ML11_1.png)

上图便是FP树的形式，还可以用一个结点链，存储每个项在树中的位置 。

### 挖掘过程
对于每个元素，按照支持度从低到高的顺序，通过结点链找到树中的位置 ，往树根遍历得到所有的前缀，然后再利用这些前缀去建立条件FP树，然后不同迭代重复，直到为空。也就是根据FP树，枚举了后缀，然后再去生成FP树，得到频繁前缀，就合并成了频繁项集。

### 代码

[Apriori的代码](https://github.com/cxlove/MachineLearning/tree/master/Apriori)

[FP-Growth的代码](https://github.com/cxlove/MachineLearning/tree/master/fpGrowth)

















