---
layout: post
title : 过拟合与正则化的那些事
description : 过拟合与正则化的那些事
category : 研究
tags : study-note MachineLearning
keywords : 
---

<font color="red">**<del>注：本文纯属总结，后附参考链接，如有侵权，联系本人。</del> --cxlove**</font>

## 过拟合(Overfitting)

过拟合是ML中最为重要的问题之一，也无须多说。

### What

通俗的说，就是在训练样本中误差极小，但是测试样本上的误差非常大。如下图中的红线，虽然完美的拟合了训练样本点，但是所得的模型显然不是我们想要的。

![多项式拟合中的过拟合](../../images/Regular_1.png =400x400)

### Why

至于过拟合产生的原因，也是极其复杂的。

1.  最通俗，也是最难解释的当属模型复杂度。下图表现了模型复杂度和误差之间的关系，当模型过于复杂时，就会出现过拟合。如上面的多项式拟合；

![误差与模型复杂度的关系](../../images/Regular_2.png =400x400)

2.  样本太少，特征维度过高。简而言之，便是样本数量与特征的关系不足以充分训练出模型，那自然效果很差；
3.  数据中噪音干扰过大。
4.  训练迭代过多，拟合了很多噪音以及没有代表性的数据，比如说决策树过于复杂、精细。

<font color="red">**<del>PS：Why和How有时候是两码事。并不是防止过拟合就不能使用复杂的模型，也不是样本越多，特征越少就好。</del>**</font>


### How

方法呢也有很多。

1.  权值衰减；
2.  交叉验证；
3.  特征工程；
4.  噪音处理；
5.  正则化。

### 题外话: bias & variance

>引用一个例子，一次打靶实验，目标是为了打到10环，但是实际上只打到了7环，那么这里面的Error就是3。但是瞄准的是9环。

偏差(bias)：bias就是说模型预期与真实值之间的差值。在上面的例子中，模型预期是9环，实际目标是10环，那么bias为1。

方差(variance)：variance反映的是模型预期与实际预测之间的差值。字面理解也知道是由于不稳定性带来的误差。上例中，虽然瞄准的是9环，但是由于射击的不稳定性，只打了7环，那么由于variance带来的误差便是2。

![bias与variance](../../images/Regular_3.png =400x400)

实际情况中，我们并不知道真实模型，于是我们引入了可能的模型，自会引入bias，又由于我们的样本数据是有限且有噪音的，所以又添加了variance。

上图也很好的反应了过拟合的问题。

**<del>好了，接下来才是正题，本来就是主要讲正则化的嘛。</del>**

## 正则化(Regularization)

大多数的监督学习，都可以抽象成以下这个优化问题：$$min_f \ loss(y - f(x) ) + \Omega (f)$$

### What

### Why

### How

## 参考(Reference)

知乎问题：[机器学习中使用「正则化来防止过拟合」到底是一个什么原理？为什么正则化项就可以防止过拟合？](http://www.zhihu.com/question/20700829)

知乎总是：[机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)有什么区别和联系？](http://www.zhihu.com/question/27068705)

