---
layout: post
title : 过拟合与正则化的那些事
description : 过拟合与正则化的那些事
category : 研究
tags : study-note MachineLearning
keywords : 
---

<font color="red">**注：本文纯属总结，后附参考链接。<del>（如有侵权，联系本人。）</del> --cxlove**</font>

# 过拟合(Overfitting)

过拟合是ML中最为重要的问题之一，也无须多说。

## What

通俗的说，就是在训练样本中误差极小，但是测试样本上的误差非常大。如下图所示，最右虽然完美的拟合了所有的样本点，但是显然所得模型不是我们所想要的。

![多项式拟合中的过拟合](/images/Regular_1.png =600x200)

## Why

至于过拟合产生的原因，也是极其复杂的。

1.  最通俗，也是最难解释的当属模型复杂度。下图表现了模型复杂度和误差之间的关系，当模型过于复杂时，就会出现过拟合。如上面的多项式拟合；

![误差与模型复杂度的关系](/images/Regular_2.png =400x400)

2.  样本太少，特征维度过高。简而言之，便是样本数量与特征的关系不足以充分训练出模型，那自然效果很差；
3.  数据中噪音干扰过大。
4.  训练迭代过多，拟合了很多噪音以及没有代表性的数据，比如说决策树过于复杂、精细。

<font color="red">**<del>PS：Why和How有时候是两码事。并不是防止过拟合就不能使用复杂的模型，也不是样本越多，特征越少就好。</del>**</font>


## How

方法呢也有很多。

1.  权值衰减；
2.  交叉验证；
3.  特征工程；
4.  噪音处理；
5.  正则化。

## 题外话: bias & variance

>引用一个例子，一次打靶实验，目标是为了打到10环，但是实际上只打到了7环，那么这里面的Error就是3。但是瞄准的是9环。

偏差(bias)：bias就是说模型预期与真实值之间的差值。在上面的例子中，模型预期是9环，实际目标是10环，那么bias为1。

方差(variance)：variance反映的是模型预期与实际预测之间的差值。字面理解也知道是由于不稳定性带来的误差。上例中，虽然瞄准的是9环，但是由于射击的不稳定性，只打了7环，那么由于variance带来的误差便是2。

![bias与variance](/images/Regular_3.png =400x400)

实际情况中，我们并不知道真实模型，于是我们引入了可能的模型，自会引入bias，又由于我们的样本数据是有限且有噪音的，所以又添加了variance。

上图也很好的反应了过拟合的问题。

**<del>好了，接下来才是正题，本来就是主要讲正则化的嘛。</del>**

# 正则化(Regularization)

监督学习的目标便是规则化参数的同时最小化误差，最小化误差当然是保证我们的数据尽可能的拟合样本数据，而规则化参数是为了防止过拟合。因为参数过多，过于复杂，会导致模型复杂度的上升，虽然误差会很小，但是容易过拟合，这和我们之前提到过拟合的重要原因符合。

大多数的监督学习，都可以抽象成以下这个优化问题：$$\min\limits_w\ \ loss(y - f(x, w) ) + \lambda * \Omega (w)$$，

## What

## Why

## How

# 参考(Reference)

知乎问题：[机器学习中使用「正则化来防止过拟合」到底是一个什么原理？为什么正则化项就可以防止过拟合？](http://www.zhihu.com/question/20700829)

知乎总是：[机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)有什么区别和联系？](http://www.zhihu.com/question/27068705)

zouxy09's blog [机器学习中的范数规则化之（一）L0、L1与L2范数](http://blog.csdn.net/zouxy09/article/details/24971995)

